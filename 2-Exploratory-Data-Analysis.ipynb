{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   Unnamed: 0                 date language likes retweets    screen_name  \\\n0         0.0  2020-01-01 19:08:15      und   0.0      0.0      Lil_COVID   \n1         1.0  2020-01-01 17:24:25       en   1.0      0.0    MattFrieman   \n2         2.0  2020-01-01 16:41:21      und   1.0      0.0  CoVid_19_0290   \n3         3.0  2020-01-01 22:04:34      und   1.0      0.0     captmakret   \n4         4.0  2020-01-01 14:05:11       en  21.0      5.0    COVID_19_ZA   \n\n                                               tweet                tweet_id  \n0                                  @rammthagreat ü§£üò≠üò≠   1.212450480137392e+18  \n1  @Crof @BioAndBaseball Anyone know if there is ...  1.2124243521694147e+18  \n2                            https://t.co/vzXNs2RAPR  1.2124135119655854e+18  \n3  @RJPilkenton @brianstelter https://t.co/oHZFv8...  1.2124948507650212e+18  \n4  Today at King Dinizulu Hospital welcoming the ...   1.212374210057851e+18  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>date</th>\n      <th>language</th>\n      <th>likes</th>\n      <th>retweets</th>\n      <th>screen_name</th>\n      <th>tweet</th>\n      <th>tweet_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>2020-01-01 19:08:15</td>\n      <td>und</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Lil_COVID</td>\n      <td>@rammthagreat ü§£üò≠üò≠</td>\n      <td>1.212450480137392e+18</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>2020-01-01 17:24:25</td>\n      <td>en</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>MattFrieman</td>\n      <td>@Crof @BioAndBaseball Anyone know if there is ...</td>\n      <td>1.2124243521694147e+18</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2.0</td>\n      <td>2020-01-01 16:41:21</td>\n      <td>und</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>CoVid_19_0290</td>\n      <td>https://t.co/vzXNs2RAPR</td>\n      <td>1.2124135119655854e+18</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.0</td>\n      <td>2020-01-01 22:04:34</td>\n      <td>und</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>captmakret</td>\n      <td>@RJPilkenton @brianstelter https://t.co/oHZFv8...</td>\n      <td>1.2124948507650212e+18</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4.0</td>\n      <td>2020-01-01 14:05:11</td>\n      <td>en</td>\n      <td>21.0</td>\n      <td>5.0</td>\n      <td>COVID_19_ZA</td>\n      <td>Today at King Dinizulu Hospital welcoming the ...</td>\n      <td>1.212374210057851e+18</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 2
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "table_df = pd.read_csv('data/1-JanTweets.csv')\n",
    "table_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Loop through the whole list and remove the coloumn headings,\n",
    "# since they repeat after every 100 entries\n",
    "\n",
    "for i in range(len(table_df)):\n",
    "    if table_df.loc[i, \"tweet\"] == \"tweet\":\n",
    "        #print(i)\n",
    "        table_df=table_df.drop(index=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "   Unnamed: 0                 date language likes retweets    screen_name  \\\n",
      "0         0.0  2020-01-01 19:08:15      und   0.0      0.0      Lil_COVID   \n",
      "1         1.0  2020-01-01 17:24:25       en   1.0      0.0    MattFrieman   \n",
      "2         2.0  2020-01-01 16:41:21      und   1.0      0.0  CoVid_19_0290   \n",
      "3         3.0  2020-01-01 22:04:34      und   1.0      0.0     captmakret   \n",
      "4         4.0  2020-01-01 14:05:11       en  21.0      5.0    COVID_19_ZA   \n",
      "\n",
      "                                               tweet                tweet_id  \n",
      "0                                  @rammthagreat ü§£üò≠üò≠   1.212450480137392e+18  \n",
      "1  @Crof @BioAndBaseball Anyone know if there is ...  1.2124243521694147e+18  \n",
      "2                            https://t.co/vzXNs2RAPR  1.2124135119655854e+18  \n",
      "3  @RJPilkenton @brianstelter https://t.co/oHZFv8...  1.2124948507650212e+18  \n",
      "4  Today at King Dinizulu Hospital welcoming the ...   1.212374210057851e+18  \n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(table_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2. Removing '@' mentions\n",
    "@ mentions in the tweets aren't really useful.\n",
    "We can remove them from all the tweets if any tweet\n",
    "mentions another user.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Unnamed: 0                         0\ndate             2020-01-01 19:08:15\nlanguage                         und\nlikes                            0.0\nretweets                         0.0\nscreen_name                Lil_COVID\ntweet              @rammthagreat ü§£üò≠üò≠\ntweet_id       1.212450480137392e+18\nName: 0, dtype: object"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 5
    }
   ],
   "source": [
    "# Get the row data from the tuple returned by iterarrows()\n",
    "next(table_df.iterrows())[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0         True\n1         True\n2        False\n3         True\n4        False\n         ...  \n23795    False\n23796    False\n23797    False\n23798    False\n23799     True\nName: tweet, Length: 23565, dtype: bool"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 6
    }
   ],
   "source": [
    "# Check for presence of @ character\n",
    "table_df[\"tweet\"].str.contains(\"@\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "how are you?\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Small example showing how to remove @ mentions\n",
    "import re\n",
    "text=\"@archity how are you?\"\n",
    "newText=re.sub('@.*? ', '', text)\n",
    "print(newText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "0                                                   ü§£üò≠üò≠\n",
      "1     Anyone know if there is a specific word for SA...\n",
      "2                               https://t.co/vzXNs2RAPR\n",
      "3                               https://t.co/oHZFv83UgZ\n",
      "4     Today at King Dinizulu Hospital welcoming the ...\n",
      "5                               https://t.co/lHpiq8F1vo\n",
      "6     #ŸÅŸÉÿ±ÿ© ..\\n#ÿßÿ≥ÿ™ÿÆÿØŸÖŸáÿß ÿ®ÿØŸÑÿß ŸÖŸÜ ÿßŸÑÿ≤ŸÖŸàÿ± ‚ù§Ô∏è\\n\\nÿ≠ÿ∑ ÿßŸÑ...\n",
      "7                              What‚Äôs a good food spot?\n",
      "8           Lmaoo damn what a way to start the new year\n",
      "9     Thank you man! so glad we get to live another ...\n",
      "10    Osea alguien te jala y debes aguantar. No seas...\n",
      "11                                            Nasty? ü•¥ü§£\n",
      "12    Bizle ne alakasƒ± var aq beni niye etiketliyon ...\n",
      "13    My 2 year old nephew walks around the house an...\n",
      "14    Earth: Makes a full rotation around the sun\\nH...\n",
      "15    Lol, yep I'm lifting now. It's like a morgue i...\n",
      "16             Love these pups. https://t.co/nxaqEDK76u\n",
      "17    plying to @ironorehopper\\nInteresting, further...\n",
      "18    Umma try to record it but it be random as hell...\n",
      "19                             So 2020 hakuna chillsüòÖüòÖüòÖ\n",
      "Name: tweet, dtype: object\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "df_clean=table_df\n",
    "\n",
    "# Function for removing @ mentions\n",
    "def remove_mentions(text):\n",
    "    newtext=re.sub('@.*? ', '', text)\n",
    "    return newtext\n",
    "\n",
    "df_clean['tweet']=table_df.tweet.apply(lambda x: remove_mentions(x))\n",
    "\n",
    "print(df_clean.head(20)[\"tweet\"])\n",
    "\n",
    "# Get the data type of each coloumn\n",
    "#print(df_clean.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Coloumn tweet type:  object\n",
      "[('coronavirus', 7943), ('the', 7341), ('de', 7002), ('a', 6008), ('of', 5632), ('to', 5190), ('in', 5181), ('China', 3948), ('#coronavirus', 3344), ('en', 3174), ('Coronavirus', 3040), ('el', 2913), ('que', 2866), ('and', 2830), ('is', 2440), ('la', 2316), ('new', 2233), ('for', 1962), ('from', 1881), ('Wuhan', 1856)]\n",
      "408123 total words\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Go through each tweet and put individual word into a list\n",
    "from collections import Counter\n",
    "\n",
    "print(\"Coloumn tweet type: \", df_clean.tweet.dtypes)\n",
    "\n",
    "word_list = []\n",
    "\n",
    "for tweet in df_clean.tweet:\n",
    "    word_list+=(tweet.split())\n",
    "\n",
    "\n",
    "#word_list[:100]\n",
    "print(Counter(word_list).most_common(20))\n",
    "\n",
    "print(len(word_list), \"total words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Some remarks-\n",
    "\n",
    "* We can see that there are several article words (a, an , the), prepositions (in, of), as well as non-English prepositions (en, de) So we need to remove such non-essential words.\n",
    "* 'coronavirus' and 'coronavirus.' (with a dot) are taken as two seperate words. So we may need to remove all such punctuation marks.\n",
    "* 'Coronavirus' and 'coronavirus' are also treaded as two different words, so we need to take care of upper/lower case letters. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "408123 total words\n",
      "75228 unique words\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Convert all the letters of words to lowercase\n",
    "word_list_lower = list(map(lambda x:x.lower(), word_list))\n",
    "\n",
    "# Get the count values of all the words\n",
    "words_counter = Counter(word_list_lower).most_common()\n",
    "\n",
    "# Convert the Counter list to a Pandas dataframe\n",
    "words_counter_df = pd.DataFrame.from_records(list(dict(words_counter).items()), columns=['word', 'count'])\n",
    "\n",
    "print(len(word_list_lower), \"total words\")\n",
    "print(len(Counter(word_list_lower)), \"unique words\")\n",
    "\n",
    "\n",
    "with open('all-words.txt', 'w', encoding=\"utf-8\") as filehandle:\n",
    "    for listitem in word_list_lower:\n",
    "        filehandle.write('%s\\n' % listitem)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "data": {
      "text/plain": "            word  count\n0    coronavirus  11232\n7   #coronavirus   4237\n8          china   4141\n11           new   3169\n15            is   2656\n17          from   2034\n18         wuhan   1892\n19             -   1792\n21             y   1530\n23          that   1436\n27      outbreak   1386\n28            no   1364\n29       chinese   1364\n30          with   1347\n31         novel   1345\n32           del   1333\n33            be   1305\n35           has   1143\n36          this   1116\n37         virus   1112",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word</th>\n      <th>count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>coronavirus</td>\n      <td>11232</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>#coronavirus</td>\n      <td>4237</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>china</td>\n      <td>4141</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>new</td>\n      <td>3169</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>is</td>\n      <td>2656</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>from</td>\n      <td>2034</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>wuhan</td>\n      <td>1892</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>-</td>\n      <td>1792</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>y</td>\n      <td>1530</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>that</td>\n      <td>1436</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>outbreak</td>\n      <td>1386</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>no</td>\n      <td>1364</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>chinese</td>\n      <td>1364</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>with</td>\n      <td>1347</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>novel</td>\n      <td>1345</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>del</td>\n      <td>1333</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>be</td>\n      <td>1305</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>has</td>\n      <td>1143</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>this</td>\n      <td>1116</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>virus</td>\n      <td>1112</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 80
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "# Remove English, French and Spanish Parts of Speech (PoS) words\n",
    "english_pos = [\"a\", \"an\", \"the\", \"in\", \"on\", \"of\", \"for\", \"to\", \"by\", \"at\", \"till\", \"until\", \"i\", \"as\", \"it\", \"he\", \"she\", \"you\", \"via\", \"and\"]\n",
    "french_pos = [\"en\", \"de\", \"le\", \"la\", \"les\", \"des\", \"√†\", \"un\", \"une\", \"se\"]\n",
    "spanish_pos = [\"el\", \"por\", \"que\"]\n",
    "\n",
    "for word1, word2, word3 in itertools.zip_longest(english_pos, french_pos, spanish_pos):\n",
    "    words_counter_df.drop(words_counter_df[words_counter_df.word == word1].index, inplace=True)\n",
    "    words_counter_df.drop(words_counter_df[words_counter_df.word == word2].index, inplace=True)\n",
    "    words_counter_df.drop(words_counter_df[words_counter_df.word == word3].index, inplace=True)\n",
    "    #print(word1, word2, word3)\n",
    "\n",
    "words_counter_df.reset_index()\n",
    "words_counter_df[:20]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "* We see that there are too many different types of PoS words that are coming across. It's better to utilize Python's NLTK library for further refinement.\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
